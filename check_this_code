import os
import json
import re
import statistics
from datetime import datetime
from collections import defaultdict
from sentence_transformers import SentenceTransformer, util
from pdf2image import convert_from_path
from your_1a_code import extract_pdf_spans, classify_headers, group_adjacent_spans

# --- Utility: Extract boost terms dynamically from persona + job ---
def extract_boost_terms(text):
    """
    Extracts meaningful keywords from persona + job description.
    Removes common stopwords and returns lowercased terms.
    """
    stopwords = {
        "the","and","or","to","for","a","of","in","on","at","with",
        "is","as","by","an","be","will","this","that","from"
    }
    words = re.findall(r"[a-zA-Z]+", text.lower())
    return [w for w in words if len(w) > 3 and w not in stopwords]

# --- Ranker Class ---
class PersonaRanker:
    def __init__(self, role, job):
        self.persona_query = f"{role}. {job}"
        self.model = SentenceTransformer("all-MiniLM-L6-v2")
        self.query_embedding = self.model.encode(self.persona_query, convert_to_tensor=True)
        # ✅ dynamic persona-driven boost terms
        self.boost_terms = extract_boost_terms(self.persona_query)
        print(f"🔍 Persona-driven boost terms: {self.boost_terms}")

    def score_section(self, title, content):
        """
        Scores a section by semantic relevance + persona keyword boost.
        Penalizes overly hyper-specific titles (e.g., “Monaco: Explore…”).
        """
        combined = f"{title}. {content}"
        section_embedding = self.model.encode(combined, convert_to_tensor=True)
        base_score = util.pytorch_cos_sim(self.query_embedding, section_embedding).item()

        # ✅ Boost if persona/job keywords appear in content
        boost = sum(1 for word in self.boost_terms if word in content.lower()) * 0.01

        # ✅ Penalize hyper-specific subheaders (e.g., “Monaco: Explore…”)
        if ":" in title and len(title.split()) > 5:
            base_score -= 0.02

        return base_score + boost

    def rank_sections(self, sections):
        """
        Scores and sorts all sections by relevance to persona/job.
        """
        for sec in sections:
            sec["score"] = self.score_section(sec["section_title"], sec["content"])
        return sorted(sections, key=lambda x: x["score"], reverse=True)

# --- Heading Matching ---
def match_heading(span_group, headers):
    """
    Finds the closest heading above the paragraph.
    """
    group_top = span_group[0]['y_top']
    group_page = span_group[0]['page']
    same_page = [h for h in headers if h['page'] == group_page]
    above = [h for h in same_page if h.get('y_top', 0) < group_top]
    if not above:
        return "General"
    return sorted(above, key=lambda h: group_top - h.get('y_top', 0))[0]['text']

# --- Section Extractor (with bullet cleanup) ---
def extract_sections_for_ranking(pdf_path, spans, images, max_size_th, mid_size, max_size):
    headers = classify_headers(spans, images, max_size_th, mid_size, max_size)
    flat_spans = [s for page in spans for s in page]
    paragraphs = group_adjacent_spans(flat_spans)

    sections = []
    for para in paragraphs:
        text = " ".join([s["text"] for s in para])
        if 15 < len(text) < 1500:
            section_title = match_heading(para, headers)

            # 🚩 1B-only cleanup: bullet/overlong header filter
            if section_title.startswith(("•", "-", "–")) or len(section_title.split()) > 10:
                section_title = text.split(".")[0][:80]  # fallback to first sentence

            sections.append({
                "document": os.path.basename(pdf_path),
                "section_title": section_title,
                "content": text,
                "page": para[0]["page"]
            })
    return sections

# --- Title Cleaning for Merge ---
def pick_clean_title(top_sections, doc_name):
    """
    Picks a clean title for the merged summary.
    - Skips bullet-point style titles and overly long titles.
    - Falls back to generic 'Summary of {doc_name}' if no good title found.
    """
    for sec in top_sections:
        title = sec["section_title"].strip()
        if not (title.startswith(("•", "-", "–")) or len(title.split()) > 10):
            return title
    return f"Summary of {doc_name}"

# --- Main Pipeline ---
def generate_round1b_output(input_json_path, pdf_dir, sections_to_merge=3):
    """
    sections_to_merge: how many top sections per PDF to merge into one summary.
    Default = 3 (can be tuned up to 5 for longer PDFs).
    """
    with open(input_json_path) as f:
        config = json.load(f)

    role = config["persona"]["role"]
    task = config["job_to_be_done"]["task"]
    documents = config["documents"]
    ranker = PersonaRanker(role, task)

    all_sections = []

    # ✅ Parse PDFs
    for doc in documents:
        filename = doc["filename"]
        pdf_path = os.path.join(pdf_dir, filename)
        print(f"📄 Processing {filename}...")

        spans, threshold_size, doc_obj = extract_pdf_spans(pdf_path)
        images = convert_from_path(pdf_path, dpi=200)

        all_sizes = sorted({s["font_size"] for page in spans for s in page}, reverse=True)
        max_size_th = all_sizes[1] if len(all_sizes) > 1 else threshold_size
        mid_size = statistics.median(all_sizes) if len(all_sizes) > 1 else max_size_th * 0.85
        max_size = all_sizes[0] if all_sizes else threshold_size

        sections = extract_sections_for_ranking(pdf_path, spans, images, max_size_th, mid_size, max_size)
        print(f"   ↳ Found {len(sections)} candidate sections")
        all_sections.extend(sections)

    print(f"🧠 Scoring sections and merging top {sections_to_merge} per PDF...")

    # ✅ Score all sections
    scored_sections = ranker.rank_sections(all_sections)

    # ✅ Group scored sections by PDF
    grouped = defaultdict(list)
    for sec in scored_sections:
        grouped[sec["document"]].append(sec)

    # ✅ Debug print top 5 sections per PDF
    for doc_name, sec_list in grouped.items():
        print(f"\n📊 Top 5 sections for {doc_name}:")
        for sec in sec_list[:5]:
            print(f"  • {sec['section_title'][:70]}... (score={sec['score']:.3f})")

    # ✅ Merge top sections into ONE summary per PDF
    merged_sections_per_pdf = {}
    for doc_name, sec_list in grouped.items():
        top_sections = sec_list[:sections_to_merge]

        # Merge the text contents into one coherent block
        merged_text = " ".join([sec["content"] for sec in top_sections])

        # ✅ Use clean title logic here
        merged_title = pick_clean_title(top_sections, doc_name)

        merged_sections_per_pdf[doc_name] = {
            "document": doc_name,
            "section_title": merged_title,
            "content": merged_text,
            "page": top_sections[0]["page"]
        }

    # ✅ Build final JSON
    final_sections = list(merged_sections_per_pdf.values())

    output = {
        "metadata": {
            "input_documents": [doc["filename"] for doc in documents],
            "persona": role,
            "job_to_be_done": task,
            "processing_timestamp": datetime.utcnow().isoformat()
        },
        "extracted_sections": [
            {
                "document": sec["document"],
                "section_title": sec["section_title"],
                "importance_rank": i + 1,
                "page_number": sec["page"]
            } for i, sec in enumerate(final_sections)
        ],
        "subsection_analysis": [
            {
                "document": sec["document"],
                "refined_text": sec["content"],
                "page_number": sec["page"]
            } for sec in final_sections
        ]
    }

    with open("challenge1b_output.json", "w") as f:
        json.dump(output, f, indent=2)

    print(f"\n✅ Generated {len(final_sections)} merged summaries (one per PDF)")
    print("✅ challenge1b_output.json saved.")
